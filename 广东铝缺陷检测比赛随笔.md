# 广东铝缺陷检测比赛

比赛介绍：

​	https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.100066.0.0.1b4733afBuhOKM&raceId=231682

比赛数据：





解决方案/解题思路：

根据比赛的相关介绍和对比赛数据的初步观察，将其定位为图像处理中的==单标签的多分类问题==，因此大方向上采用分类模型去解答，目前较为主流的分类模型有resnet，inception v4， densenet，为此，打算从这几个网络着手！

1）将train数据进行切分为训练数据和验证数据：

比赛给了两个部分的数据，一部分是有标签的训练数据，还有一部分是没有标签的测试数据，为了更快的算法迭代以及验证模型效果，需要先将有标签的训练数据进行切分，切为两个部分：train与val数据，采用sklearn中的sklearn.model_selection模块下的train_test_split方法，该数据集是根据文件夹的名字来标注类别的，因此首先遍历文件得到相应的label，参考其他人的代码（https://github.com/Herbert95/tianchi_lvcai/blob/master/gen_label_csv.py），得到图片的路径以及对应的label，代码如下：

```python
  1 import os
  2 import math
  3 import numpy as np
  4 import pandas as pd
  5 import os.path as osp
  6 
  7 label_warp = {'正常': 0,
  8               '不导电': 1,
  9               '擦花': 2,
 10               '横条压凹': 3,
 11               '桔皮': 4,
 12               '漏底': 5,
 13               '碰伤': 6,
 14               '起坑': 7,
 15               '凸粉': 8,
 16               '涂层开裂': 9,
 17               '脏点': 10,
 18               '其他': 11,
 19               }
 20 
 21 # train data
 22 data_path = 'data/guangdong_round1_train2_20180916'
 23 img_path, label = [], []
 24 
 25 print(os.listdir(data_path))
 26 for first_path in os.listdir(data_path):
 27     if first_path == '.DS_Store':
 28         continue
 29     first_path = osp.join(data_path, first_path)
 30     if '无瑕疵样本' in first_path:
 31         for img in os.listdir(first_path):
 32             img_path.append(osp.join(first_path, img))
 33             label.append('正常')
 34     else:
 35         for second_path in os.listdir(first_path):
 36             if second_path == '.DS_Store':
 37                 continue
 38             defect_label = second_path
 39             second_path = osp.join(first_path, second_path)
 40             if defect_label != '其他':
 41                 for img in os.listdir(second_path):
 42                     img_path.append(osp.join(second_path, img))
 43                     label.append(defect_label)
 44             else:
 45                 for third_path in os.listdir(second_path):
 46                     third_path = osp.join(second_path, third_path)
 47                     if osp.isdir(third_path):
 48                         for img in os.listdir(third_path):
 49                             if 'DS_Store' not in img:
 50                                 img_path.append(osp.join(third_path, img))
 51                                 label.append(defect_label)
 52 
 53 label_file = pd.DataFrame({'img_path': img_path, 'label': label})
 54 label_file['label'] = label_file['label'].map(label_warp)
 55 
 56 label_file.to_csv('data/label.csv', index=False)
 57 
 58 # test data
 59 test_data_path = 'data/guangdong_round1_test_a_20180916'
 60 all_test_img = os.listdir(test_data_path)
 61 test_img_path = []
 62 
 63 for img in all_test_img:
 64     if osp.splitext(img)[1] == '.jpg':
 65         test_img_path.append(osp.join(test_data_path, img))
 66 
 67 test_file = pd.DataFrame({'img_path': test_img_path})
 68 test_file.to_csv('data/test.csv', index=False)
```

得到了文件的路径以及对应的文件类别，分析数据特征，画出相应的统计图：

统计类别：

![guangdong_bar](/Users/majian/Documents/machine learning/广东铝缺陷检测比赛/data/guangdong_bar.png)



![guangdong_pie](/Users/majian/Documents/machine learning/广东铝缺陷检测比赛/data/guangdong_pie.png)

从统计图上可以得出如下结论：

1. 类别极为不均衡，其中norm的占比为47.7%，因此后续对于样本的采样需要进行根据类别进行分层采样

2. 有些类别的数据量只有几十张，后续需要考虑数据增强



采用sklearn中train_test_split方法来切割训练与验证集，由于本数据集的类别不均衡，因此需要采用==分层抽样==，代码如下：

```python
  1 import pandas as pd
  2 import numpy as np
  3 from sklearn.model_selection import train_test_split
  4 
  5 # 读取训练图片列表
  6 all_data = pd.read_csv('data/label.csv')
  7 print('len of all_data:',len(all_data))
  8 # 分离训练集和测试集，stratify参数用于分层抽样
  9 train_data_list, val_data_list = train_test_split(all_data, test_size=0.3, random_state=666, stratify=all_data['label'])
 10 
 11 print(train_data_list)
```

2）构建网络：densenet